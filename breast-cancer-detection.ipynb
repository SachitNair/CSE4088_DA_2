{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# %%capture\n# Source: https://www.kaggle.com/code/remekkinas/fast-dicom-processing-1-6-2x-faster?scriptVersionId=113360473\n!pip install /kaggle/input/rsnamodules/dicomsdl-0.109.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl \n\ntry:\n    import pylibjpeg\nexcept:\n   !pip install /kaggle/input/rsna-2022-whl/{pylibjpeg-1.4.0-py3-none-any.whl,python_gdcm-3.0.15-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl}","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-10T04:02:41.052091Z","iopub.execute_input":"2023-04-10T04:02:41.053421Z","iopub.status.idle":"2023-04-10T04:03:01.931167Z","shell.execute_reply.started":"2023-04-10T04:02:41.053352Z","shell.execute_reply":"2023-04-10T04:03:01.928810Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Install Tensorflow Keras EfficientNetV2\n!pip install --no-deps  /kaggle/input/kerasefficientnetv2/keras_efficientnet_v2-1.2.2-py3-none-any.whl","metadata":{"execution":{"iopub.status.busy":"2023-04-10T03:52:26.957307Z","iopub.execute_input":"2023-04-10T03:52:26.958044Z","iopub.status.idle":"2023-04-10T03:52:30.405994Z","shell.execute_reply.started":"2023-04-10T03:52:26.958014Z","shell.execute_reply":"2023-04-10T03:52:30.404474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport pylibjpeg\nimport pydicom\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport dicomsdl as dicoml\nimport pydicom\n\nfrom joblib import Parallel, delayed\nfrom tqdm.notebook import tqdm\nfrom multiprocessing import cpu_count\n\nimport keras_efficientnet_v2\nimport cv2\nimport glob\nimport importlib\nimport os\nimport joblib\nimport time\n\n# Tensorflow and CV2 set number of threads to 1 for speedup in parallell function mapping\ntf.config.threading.set_inter_op_parallelism_threads(num_threads=1)\ncv2.setNumThreads(1)\n\n# Pandas DataFrame Display Options\npd.options.display.max_colwidth = 99","metadata":{"execution":{"iopub.status.busy":"2023-04-10T04:03:38.356542Z","iopub.execute_input":"2023-04-10T04:03:38.357502Z","iopub.status.idle":"2023-04-10T04:03:47.092668Z","shell.execute_reply.started":"2023-04-10T04:03:38.357446Z","shell.execute_reply":"2023-04-10T04:03:47.091544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IS_INTERACTIVE = os.environ['KAGGLE_KERNEL_RUN_TYPE'] == 'Interactive'\n\nTARGET_HEIGHT = 1344\nTARGET_WIDTH = 768\nN_CHANNELS = 1\nINPUT_SHAPE = (TARGET_HEIGHT, TARGET_WIDTH, N_CHANNELS)\nTARGET_HEIGHT_WIDTH_RATIO = TARGET_HEIGHT / TARGET_WIDTH\nTHRESHOLD_BEST = 0.5\nCLAHE = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(32, 32))","metadata":{"execution":{"iopub.status.busy":"2023-04-10T04:10:11.378141Z","iopub.execute_input":"2023-04-10T04:10:11.378825Z","iopub.status.idle":"2023-04-10T04:10:11.385732Z","shell.execute_reply.started":"2023-04-10T04:10:11.378788Z","shell.execute_reply":"2023-04-10T04:10:11.384593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def smooth(l):\n    kernel_size = int(len(l) * 0.01)\n    kernel = np.ones(kernel_size) / kernel_size\n    return np.convolve(l, kernel, mode='same')\n\ndef get_x_offset(image, max_col_sum_ratio_threshold=0.05):\n    margin = 0\n    sums = smooth(image.sum(axis=0).squeeze())\n    sums_argmax = sums[:int(image.shape[1] * 0.75)].argmax()\n    sums_threshold = sums.max() * max_col_sum_ratio_threshold\n    first_non_zoro_column_found = False\n    \n    for offset, s in enumerate(sums):\n        if s < sums_threshold and first_non_zoro_column_found:\n            return min(image.shape[1], offset + margin)\n        elif s > sums_threshold and offset > sums_argmax:\n            first_non_zoro_column_found = True\n        \n    return offset\n\ndef get_y_offsets(image, max_row_sum_ratio_threshold=0.10):\n    margin = 0\n    sums = smooth(image.sum(axis=1).squeeze())\n    sums_argmax = int(image.shape[0] * 0.25) + sums[int(image.shape[0] * 0.25):int(image.shape[0] * 0.75)].argmax()\n    sum_threshold = sums.max() * max_row_sum_ratio_threshold\n    offset_bottom = 0\n    offset_top = image.shape[0]\n    offset_top_set = False\n\n    # Bottom offset\n    for offset, s in enumerate(sums):\n        if s < sum_threshold and not offset_top_set:\n            offset_bottom += 1\n        else:\n            break\n            \n    for offset, s in enumerate(reversed(sums)):\n        if s > sum_threshold and not offset_top_set:\n            offset_top = image.shape[0] - (offset + 1)\n            break\n            \n    return max(0, offset_bottom - margin), min(image.shape[0], offset_top + margin)\n\ndef crop(image, debug=False):\n    x_offset = get_x_offset(image)\n    offset_bottom, offset_top = get_y_offsets(image[:,:x_offset])\n    \n    image = image[offset_bottom:offset_top:,:x_offset]\n        \n    return image","metadata":{"execution":{"iopub.status.busy":"2023-04-10T04:21:07.762874Z","iopub.execute_input":"2023-04-10T04:21:07.763496Z","iopub.status.idle":"2023-04-10T04:21:07.777450Z","shell.execute_reply.started":"2023-04-10T04:21:07.763459Z","shell.execute_reply":"2023-04-10T04:21:07.776249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process(file_path, size=None, crop_image=False, apply_clahe=False, debug=False, save=False):\n    # Read Dicom File\n    dicom = pydicom.dcmread(file_path)\n    image = dicom.pixel_array\n\n    # Normalize [0,1] range\n    image = (image - image.min()) / (image.max() - image.min())\n\n    if dicom.PhotometricInterpretation == \"MONOCHROME1\":  \n        image = 1 - image\n\n    # Convert to uint8 image in range [0, 255]\n    image = (image * 255).astype(np.uint8)\n    \n    # Flip T0 Left/Right Orientation\n    h0, w0 = image.shape\n    if image[:,int(-w0 * 0.10):].sum() > image[:,:int(w0 * 0.10)].sum():\n        image = np.flip(image, axis=1)\n    \n    # Save original image\n    if debug:\n        image0 = np.copy(image)\n    \n    # Always crop 10 pixels for weird border noise/lines\n    image = image[int(h0 * 2e-2):-int(h0 * 2e-2),int(w0 * 2e-2):-int(w0 * 2e-2)]\n    \n    if crop_image:\n        image = crop(image, debug=debug)\n        \n    # Resize\n    if size is not None:\n        # Pad black pixels to make square image\n        h, w = image.shape\n        if (h / w) > TARGET_HEIGHT_WIDTH_RATIO:\n            pad = int(h / TARGET_HEIGHT_WIDTH_RATIO - w)\n            image = np.pad(image, [[0,0], [0, pad]])\n            h, w = image.shape\n        else:\n            pad = int(0.50 * (w * TARGET_HEIGHT_WIDTH_RATIO - h))\n            image = np.pad(image, [[pad, pad], [0,0]])\n            h, w = image.shape\n        # Resize\n        image = cv2.resize(image, size, interpolation=cv2.INTER_AREA)\n        \n    # Apply CLAHE contrast enhancement\n    if apply_clahe:\n        image = CLAHE.apply(image)\n        \n    # Save Only\n    if save:\n        image_id = file_path.split('/')[-1].split('.')[0]\n        cv2.imwrite(f'{image_id}.png', image)","metadata":{"execution":{"iopub.status.busy":"2023-04-10T04:23:21.843712Z","iopub.execute_input":"2023-04-10T04:23:21.844539Z","iopub.status.idle":"2023-04-10T04:23:21.858122Z","shell.execute_reply.started":"2023-04-10T04:23:21.844498Z","shell.execute_reply":"2023-04-10T04:23:21.856575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def normalize(image):\n    image = tf.repeat(image, repeats=3, axis=3)\n    image = tf.cast(image, tf.float32)\n    image = tf.keras.applications.imagenet_utils.preprocess_input(image, mode='torch')\n\n    return image","metadata":{"execution":{"iopub.status.busy":"2023-04-10T04:23:46.562765Z","iopub.execute_input":"2023-04-10T04:23:46.563231Z","iopub.status.idle":"2023-04-10T04:23:46.570586Z","shell.execute_reply.started":"2023-04-10T04:23:46.563190Z","shell.execute_reply":"2023-04-10T04:23:46.568994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_model():\n    # Inputs, note the names are equal to the dictionary keys in the dataset\n    image = tf.keras.layers.Input(INPUT_SHAPE, name='image', dtype=tf.uint8)\n\n    # Normalize Input\n    image_norm = normalize(image)\n\n    # CNN Prediction\n    outputs = keras_efficientnet_v2.EfficientNetV2T(\n        input_shape=[TARGET_HEIGHT, TARGET_WIDTH, 3],\n        pretrained=None,\n        num_classes=1,\n        classifier_activation='sigmoid',\n        dropout=0.30,\n    )(image_norm)\n\n    model = tf.keras.models.Model(inputs=image, outputs=outputs)\n    \n    model.load_weights('/kaggle/input/my-balanced-rsna-effnetv2t-wts/model.h5')\n\n    model.trainable = False\n\n    model.compile()\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-04-10T04:29:35.622746Z","iopub.execute_input":"2023-04-10T04:29:35.623434Z","iopub.status.idle":"2023-04-10T04:29:35.631498Z","shell.execute_reply.started":"2023-04-10T04:29:35.623394Z","shell.execute_reply":"2023-04-10T04:29:35.630342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Pretrained File Path: '/kaggle/input/sartorius-training-dataset/model.h5'\ntf.keras.backend.clear_session()\n# enable XLA optmizations\ntf.config.optimizer.set_jit(True)\n\nmodel = get_model()","metadata":{"execution":{"iopub.status.busy":"2023-04-10T04:29:36.166706Z","iopub.execute_input":"2023-04-10T04:29:36.167110Z","iopub.status.idle":"2023-04-10T04:29:42.776229Z","shell.execute_reply.started":"2023-04-10T04:29:36.167075Z","shell.execute_reply":"2023-04-10T04:29:42.775160Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot model summary\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-04-10T04:29:48.488977Z","iopub.execute_input":"2023-04-10T04:29:48.489709Z","iopub.status.idle":"2023-04-10T04:29:48.554389Z","shell.execute_reply.started":"2023-04-10T04:29:48.489669Z","shell.execute_reply":"2023-04-10T04:29:48.553335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model is not trainable\n# model.fit()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/rsna-breast-cancer-detection/test.csv')\n\ndef get_file_path(args):\n    patient_id, image_id = args\n    return f'/kaggle/input/rsna-breast-cancer-detection/test_images/{patient_id}/{image_id}.dcm'\n    \ntest['file_path'] = test[['patient_id', 'image_id']].apply(get_file_path, axis=1)\n\ndisplay(test.info())\ndisplay(test.head())","metadata":{"execution":{"iopub.status.busy":"2023-04-10T04:30:21.615048Z","iopub.execute_input":"2023-04-10T04:30:21.615804Z","iopub.status.idle":"2023-04-10T04:30:21.673212Z","shell.execute_reply.started":"2023-04-10T04:30:21.615761Z","shell.execute_reply":"2023-04-10T04:30:21.672098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission = pd.read_csv('/kaggle/input/rsna-breast-cancer-detection/sample_submission.csv')\n\ndisplay(sample_submission.info())\ndisplay(sample_submission.head())","metadata":{"execution":{"iopub.status.busy":"2023-04-10T04:31:00.600656Z","iopub.execute_input":"2023-04-10T04:31:00.601054Z","iopub.status.idle":"2023-04-10T04:31:00.629543Z","shell.execute_reply.started":"2023-04-10T04:31:00.601022Z","shell.execute_reply":"2023-04-10T04:31:00.628129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preprocess a single image and saves it\ndef preprocess_and_save_image(args):\n    (patient_id, laterality), g = args\n    cancer = 0.0\n    for row_idx, row in g.iterrows():\n        process(row['file_path'], size=(TARGET_WIDTH, TARGET_HEIGHT), crop_image=True, save=True)","metadata":{"execution":{"iopub.status.busy":"2023-04-10T04:31:09.901067Z","iopub.execute_input":"2023-04-10T04:31:09.901614Z","iopub.status.idle":"2023-04-10T04:31:09.907858Z","shell.execute_reply.started":"2023-04-10T04:31:09.901571Z","shell.execute_reply":"2023-04-10T04:31:09.906704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preprocess all images in parallel using Joblib\njobs = [joblib.delayed(preprocess_and_save_image)(args) for args in test.groupby(['patient_id', 'laterality'])]\nSUBMISSION_ROWS = joblib.Parallel(\n    n_jobs=cpu_count(),\n    verbose=1,\n    backend='multiprocessing',\n    prefer='threads',\n)(jobs)","metadata":{"execution":{"iopub.status.busy":"2023-04-10T04:31:32.532411Z","iopub.execute_input":"2023-04-10T04:31:32.533553Z","iopub.status.idle":"2023-04-10T04:31:35.830820Z","shell.execute_reply.started":"2023-04-10T04:31:32.533498Z","shell.execute_reply":"2023-04-10T04:31:35.828362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SUBMISSION_ROWS = []\n\nfor (patient_id, laterality), g in tqdm(test.groupby(['patient_id', 'laterality'])):\n    cancer = 0\n    for row_idx, row in g.iterrows():\n        # Load Image\n        image_id = row['image_id']\n        image = cv2.imread(f'{image_id}.png', -1)\n        # Expand to Batch HxW -> 1xHxWx1\n        image = np.expand_dims(image, [0, 3])\n        # Make Prediction\n        cancer += model.predict_on_batch(image).squeeze() / len(g)\n        # Remove Image PNG\n        os.remove(f'{image_id}.png')\n        \n    # Add Submission Row\n    SUBMISSION_ROWS.append({\n        'prediction_id': f'{patient_id}_{laterality}',\n        #'cancer': np.int8(cancer > THRESHOLD_BEST),\n        'cancer': cancer,\n    })","metadata":{"execution":{"iopub.status.busy":"2023-04-10T04:36:03.991454Z","iopub.execute_input":"2023-04-10T04:36:03.992522Z","iopub.status.idle":"2023-04-10T04:36:22.347369Z","shell.execute_reply.started":"2023-04-10T04:36:03.992480Z","shell.execute_reply":"2023-04-10T04:36:22.346094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create DataFrame from submission rows\nsubmission_df = pd.DataFrame(SUBMISSION_ROWS)\n\ndisplay(submission_df.info())\ndisplay(submission_df.head())","metadata":{"execution":{"iopub.status.busy":"2023-04-10T04:45:37.570447Z","iopub.execute_input":"2023-04-10T04:45:37.571120Z","iopub.status.idle":"2023-04-10T04:45:37.604128Z","shell.execute_reply.started":"2023-04-10T04:45:37.571075Z","shell.execute_reply":"2023-04-10T04:45:37.602911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df.to_csv('submission.csv', columns=['prediction_id','cancer'],index=False)","metadata":{"execution":{"iopub.status.busy":"2023-04-10T04:45:56.629342Z","iopub.execute_input":"2023-04-10T04:45:56.629738Z","iopub.status.idle":"2023-04-10T04:45:56.643194Z","shell.execute_reply.started":"2023-04-10T04:45:56.629705Z","shell.execute_reply":"2023-04-10T04:45:56.642044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sanity Check\ndisplay(pd.read_csv('submission.csv').head())","metadata":{"execution":{"iopub.status.busy":"2023-04-10T04:46:04.503327Z","iopub.execute_input":"2023-04-10T04:46:04.504089Z","iopub.status.idle":"2023-04-10T04:46:04.519800Z","shell.execute_reply.started":"2023-04-10T04:46:04.504053Z","shell.execute_reply":"2023-04-10T04:46:04.518241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}